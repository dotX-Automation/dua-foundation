# Base unit for Nvidia Jetson Nano platforms based on JetPack 4.6.1.
#
# Roberto Masocco <r.masocco@dotxautomation.com>
#
# April 15, 2023

# Copyright 2024 dotX Automation s.r.l.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# BUILD THIS WITH:
# --network host

# Start from a Ubuntu 20.04 base image for linux/arm64/v8
FROM --platform=linux/arm64/v8 ubuntu:20.04

# SoC and Linux4Tegra versions
ARG L4T_RELEASE_MAJOR=32.7
ARG L4T_RELEASE_MINOR=1
ARG L4T_RELEASE=$L4T_RELEASE_MAJOR.$L4T_RELEASE_MINOR
ARG CUDA=10.2
ARG SOC="t210"

ENV DEBIAN_FRONTEND=noninteractive

# Create internal users group
RUN groupadd -r internal

# Configure ROS 2 repository
RUN apt-get update && \
  apt-get install -y --no-install-recommends ca-certificates curl && \
  curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg && \
  echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release && echo $UBUNTU_CODENAME) main" | tee /etc/apt/sources.list.d/ros2.list > /dev/null && \
  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*/apt/lists/*

# Install basic utilities, dependencies, and development tools
# These include:
# - C/C++ toolchain and debuggers
# - Python 3 interpreter, testers, basic modules and scientific libraries
# - Linters
# - OpenCV dependencies for ARMv8 systems
# - Boost C++ libraries
# - System utilities
# - Zsh shell
# - ROS 2 Humble Hawksbill development tools and dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
  apt-utils \
  build-essential \
  ccache \
  cmake \
  cppcheck \
  dialog \
  dirmngr \
  dmidecode \
  file \
  freeglut3 \
  freeglut3-dev \
  fuse \
  g++ \
  gcc \
  gdb \
  gfortran \
  git \
  gnupg2 \
  gstreamer1.0-tools \
  htop \
  iproute2 \
  less \
  lcov \
  libasio-dev \
  libatlas-base-dev \
  libavcodec-dev \
  libavformat-dev \
  libavresample-dev \
  libblas-dev \
  libboost-all-dev \
  libcanberra-gtk* \
  libdc1394-22-dev \
  libfaac-dev \
  libgeographic-dev \
  libgflags-dev \
  libglu1-mesa-dev \
  libgoogle-glog-dev \
  libgstreamer1.0-dev \
  libgstreamer-plugins-base1.0-dev \
  libgtk2.0-dev \
  libgtk-3-dev \
  libhdf5-dev \
  libjpeg-dev \
  liblapack-dev \
  libmp3lame-dev \
  libopenblas-dev \
  libopencore-amrnb-dev \
  libopencv-dev \
  libpng-dev \
  libprotobuf-dev \
  libswscale-dev \
  libtbb2 \
  libtbb-dev \
  libtheora-dev \
  libtiff-dev \
  libtinyxml2-dev \
  libv4l-dev \
  libvorbis-dev \
  libx264-dev \
  libxine2-dev \
  libxml2-utils \
  libxvidcore-dev \
  locales \
  lsb-core \
  lsb-release \
  make \
  manpages-dev \
  manpages-posix-dev \
  minicom \
  nano \
  ninja-build \
  openssh-client \
  pkg-config \
  protobuf-compiler \
  python-dev-is-python3 \
  python-is-python3 \
  python3 \
  python3-argcomplete \
  python3-autopep8 \
  python3-dev \
  python3-numpy \
  python3-pip \
  python3-pygments \
  python3-pytest-cov \
  python3-pytest-pylint \
  python3-vcstool \
  python3-vcstools \
  python3-venv \
  qt5-default \
  ros-dev-tools \
  screen \
  shellcheck \
  software-properties-common \
  sudo \
  uncrustify \
  unzip \
  v4l-utils \
  valgrind \
  vim \
  wget \
  whois \
  zip \
  zsh \
  zsh-doc && \
  add-apt-repository universe && \
  apt-get autoremove -y && \
  apt-get autoclean && \
  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*/apt/lists/*

# Configure Git to accept different ownerships for local repository clones
RUN git config --system --add safe.directory '*'

# Configure system for L4T
# NOTE: This is old stuff: it requires us to place environment variables and
# files that can be hooked in by the Nvidia runtime.
ADD --chown=root:root https://repo.download.nvidia.com/jetson/jetson-ota-public.asc /etc/apt/trusted.gpg.d/jetson-ota-public.asc
RUN chmod 644 /etc/apt/trusted.gpg.d/jetson-ota-public.asc && \
  echo "deb https://repo.download.nvidia.com/jetson/common r$L4T_RELEASE_MAJOR main" > /etc/apt/sources.list.d/nvidia-l4t-apt-source.list && \
  echo "deb https://repo.download.nvidia.com/jetson/${SOC} r$L4T_RELEASE_MAJOR main" >> /etc/apt/sources.list.d/nvidia-l4t-apt-source.list && \
  echo "/usr/lib/aarch64-linux-gnu/tegra" >> /etc/ld.so.conf.d/nvidia-tegra.conf && \
  echo "/usr/lib/aarch64-linux-gnu/tegra-egl" >> /etc/ld.so.conf.d/nvidia-tegra.conf && \
  rm /usr/share/glvnd/egl_vendor.d/50_mesa.json && \
  mkdir -p /usr/share/glvnd/egl_vendor.d/ && \
  echo '{"file_format_version" : "1.0.0" , "ICD" : { "library_path" : "libEGL_nvidia.so.0" }}' > /usr/share/glvnd/egl_vendor.d/10_nvidia.json && \
  mkdir -p /usr/share/egl/egl_external_platform.d/ && \
  echo '{"file_format_version" : "1.0.0" , "ICD" : { "library_path" : "libnvidia-egl-wayland.so.1" }}' > /usr/share/egl/egl_external_platform.d/nvidia_wayland.json && \
  echo "/usr/local/cuda-$CUDA/targets/aarch64-linux/lib" >> /etc/ld.so.conf.d/nvidia.conf && \
  ldconfig

# Set environment variables for L4T
ENV PATH=/usr/local/cuda-$CUDA/bin:/usr/local/cuda/bin:${PATH}
ENV LD_LIBRARY_PATH=/usr/local/cuda-$CUDA/targets/aarch64-linux/lib:${LD_LIBRARY_PATH}
ENV LD_LIBRARY_PATH=/opt/nvidia/vpi1/lib64:${LD_LIBRARY_PATH}
ENV LD_LIBRARY_PATH=/usr/lib/aarch64-linux-gnu/tegra:${LD_LIBRARY_PATH}
ENV LD_LIBRARY_PATH=/usr/lib/aarch64-linux-gnu/tegra-egl:${LD_LIBRARY_PATH}
ENV NVIDIA_VISIBLE_DEVICES=all
ENV NVIDIA_DRIVER_CAPABILITIES=all
ENV OPENBLAS_CORETYPE=ARMV8

# Install and set GCC 8 as default (required by NVCC)
RUN apt-get update && apt-get install -y --no-install-recommends \
  gcc-8 \
  g++-8 && \
  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*/apt/lists/* && \
  update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8 && \
  update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-8 8

# Install CUDA Toolkit 10.2
RUN apt-get update && apt-get install -y --no-install-recommends \
  cuda-toolkit-10-2 && \
  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*/apt/lists/*

# Install Java 11
RUN apt-get update && apt-get install -y --no-install-recommends \
  ant \
  openjdk-11-jre \
  openjdk-11-jdk \
  libvecmath-java && \
  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*/apt/lists/* && \
  update-alternatives --set java $(update-alternatives --list java | grep "java-11")

# Create a Python virtual environment and install packages in it
WORKDIR /opt
RUN --mount=type=bind,source=requirements_jetson.txt,target=/opt/requirements_jetson.txt \
  python3 -m venv --system-site-packages dua-venv && \
  . dua-venv/bin/activate && \
  pip install -U -r requirements_jetson.txt && \
  chgrp -R internal /opt/dua-venv && \
  chmod -R g+rw /opt/dua-venv
WORKDIR /root

# Install jetson-stats in the system environment (as it requires)
RUN yes | sudo pip3 install -U jetson-stats

# Ensure that the Python environment is correctly sourced
# NOTE: System path is the output of:
# python3 -c "from distutils.sysconfig import get_python_lib; print(get_python_lib())"
ENV PYTHONPATH=/opt/dua-venv/lib/python3.8/site-packages:/usr/lib/python3.8/site-packages${PYTHONPATH:+:${PYTHONPATH}}

# Configure language and locale
RUN locale-gen en_US.UTF-8 && \
  update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8
ENV LANG=en_US.UTF-8

# Build ROS 2 Humble Hawksbill from source
# NOTE: The procedure is not obvious, so here is a brief explanation:
# 1. Create a workspace
# 2. Clone the repos file, containing the default plus some extras
# 3. Initialize rosdep
# 4. Update rosdep
# 5. Install dependencies via rosdep
# 6. Install OpenCV 4.2.0 with development files, which may have been deleted by rosdep
# 7. Build the workspace
# 8. Remove build and log files
# Step 7 highly depends on the platform and build environment.
# In this case, we need to:
# - Install a version of OpenCV that is compatible with this codebase, hence 4.2.0
# - Ensure that the Python 3.8.0 environment is found by CMake (it's the one preinstalled by Nvidia)
# - Ensure that OpenCV 4.2.0 is found by CMake
WORKDIR /opt
RUN --mount=type=bind,source=ros2_humble_repos_base.yml,target=/opt/repos.yml \
  mkdir -p ros/humble/src && \
  cd ros/humble && \
  vcs import --input /opt/repos.yml src && \
  rosdep init && \
  rosdep update --rosdistro=humble && \
  apt-get update && \
  rosdep install \
    --rosdistro=humble \
    --from-paths src \
    --ignore-src \
    -y \
    --skip-keys="fastcdr rti-connext-dds-6.0.1 rviz2 rviz_common rviz_default_plugins rviz_rendering urdfdom_headers" && \
  apt-get install -y --no-install-recommends libopencv-dev && \
  colcon build \
    --merge-install \
    --cmake-args \
      -DPython3_EXECUTABLE=/usr/bin/python3.8 \
      -DPython3_LIBRARY=/usr/lib/python3.8/config-3.8-aarch64-linux-gnu/libpython3.8.so \
      -DPython3_INCLUDE_DIR=/usr/include/python3.8 \
      -DOpenCV_DIR=/usr/lib/aarch64-linux-gnu/cmake/opencv4 \
    --ament-cmake-args \
      -DPython3_EXECUTABLE=/usr/bin/python3.8 \
      -DPython3_LIBRARY=/usr/lib/python3.8/config-3.8-aarch64-linux-gnu/libpython3.8.so \
      -DPython3_INCLUDE_DIR=/usr/include/python3.8 \
      -DOpenCV_DIR=/usr/lib/aarch64-linux-gnu/cmake/opencv4 \
    --packages-ignore vision_msgs_rviz_plugins && \
  rm -rf build log src && \
  rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*/apt/lists/* && \
  chgrp -R internal /opt/ros && \
  chmod -R g+rw /opt/ros
WORKDIR /root

# Configure ROS Middleware implementation to use
ENV RMW_IMPLEMENTATION=rmw_fastrtps_cpp

# Build and install Eigen3
WORKDIR /opt
RUN git clone --single-branch --branch '3.4.0' --depth 1 https://gitlab.com/libeigen/eigen.git && \
  cd eigen && \
  mkdir build && \
  cd build && \
  cmake -DCMAKE_INSTALL_PREFIX=/usr/local .. && \
  make -j$(nproc --all) && \
  make install && \
  cd .. && \
  rm -rf build && \
  chgrp -R internal /opt/eigen && \
  chmod -R g+rw /opt/eigen
WORKDIR /root

# Build and install OpenCV (with extra modules aka "contrib") with CUDA support
WORKDIR /opt
RUN . dua-venv/bin/activate && \
  git clone --single-branch --branch '4.7.0' --depth 1 https://github.com/opencv/opencv.git && \
  git clone --single-branch --branch '4.7.0' --depth 1 https://github.com/opencv/opencv_contrib.git && \
  cd opencv && \
  mkdir build && \
  cd build && \
  cmake \
    -D CMAKE_BUILD_TYPE=RELEASE \
    -D CMAKE_INSTALL_PREFIX=/usr/local \
    -D CUDA_ARCH_BIN="5.3" \
    -D CUDA_ARCH_PTX="" \
    -D CUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda \
    -D EIGEN_INCLUDE_PATH=/usr/local/include/eigen3 \
    -D OPENCV_GENERATE_PKGCONFIG=ON \
    -D OPENCV_ENABLE_NONFREE=ON \
    -D OPENCV_EXTRA_MODULES_PATH=/opt/opencv_contrib/modules \
    -D WITH_CUBLAS=ON \
    -D WITH_CUDA=ON \
    -D WITH_CUDNN=OFF \
    -D WITH_EIGEN=ON \
    -D WITH_OPENCL=OFF \
    -D WITH_QT=OFF \
    -D WITH_TBB=ON \
    -D WITH_V4L=ON \
    -D ENABLE_FAST_MATH=ON \
    -D ENABLE_NEON=ON \
    -D CUDA_FAST_MATH=ON \
    -D OPENCV_DNN_CUDA=OFF \
    -D BUILD_TBB=ON \
    -D BUILD_EXAMPLES=OFF \
    -D BUILD_TESTS=OFF \
    -D BUILD_opencv_python2=OFF \
    -D BUILD_opencv_python3=ON \
    -D INSTALL_PYTHON_EXAMPLES=OFF \
    -D INSTALL_C_EXAMPLES=OFF \
    -D PYTHON_EXECUTABLE=$(which python2) \
    -D PYTHON3_EXECUTABLE=$(which python3) \
    -D PYTHON3_INCLUDE_DIR=$(python3 -c "from distutils.sysconfig import get_python_inc; print(get_python_inc())") \
    -D PYTHON3_PACKAGES_PATH=$(python3 -c "from distutils.sysconfig import get_python_lib; print(get_python_lib())") \
    -D OPENCV_PYTHON3_INSTALL_PATH=$(python3 -c "from distutils.sysconfig import get_python_lib; print(get_python_lib())") \
    .. && \
  make -j$(nproc --all) && \
  make install && \
  ldconfig && \
  cd .. && \
  rm -rf build && \
  chgrp -R internal /opt/opencv && \
  chmod -R g+rw /opt/opencv && \
  chgrp -R internal /opt/opencv_contrib && \
  chmod -R g+rw /opt/opencv_contrib
WORKDIR /root

# Install zenoh-bridge-ros2dds
# NOTE: Version 0.10.1-rc.2.
WORKDIR /usr/local/bin
RUN wget -O - https://github.com/eclipse-zenoh/zenoh-plugin-ros2dds/releases/download/0.10.1-rc.2/zenoh-bridge-ros2dds-0.10.1-rc.2-aarch64-unknown-linux-gnu.zip | funzip > zenoh-bridge-ros2dds && \
  chmod a+x zenoh-bridge-ros2dds
WORKDIR /root

# Build and install dua-utils
# The ARG allows us to break cache and rebuild from here upon each new version
WORKDIR /opt
ARG DUA_UTILS_VERSION=20240719-1547
RUN . dua-venv/bin/activate && \
  echo "Building dua-utils version ${DUA_UTILS_VERSION}" && \
  git clone https://github.com/dotX-Automation/dua-utils.git ros/dua-utils && \
  cd ros/dua-utils && \
  . /opt/ros/humble/install/setup.sh && \
  colcon build --merge-install && \
  rm -rf build log && \
  chgrp -R internal /opt/ros/dua-utils && \
  chmod -R g+rw /opt/ros/dua-utils
WORKDIR /root

ENV DEBIAN_FRONTEND=dialog

# Finalize image
LABEL description="DUA base unit for Nvidia Jetson Nano platforms"
LABEL platform="linux/arm64/v8"
CMD ["bash"]
